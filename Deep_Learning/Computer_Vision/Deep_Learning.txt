防止过拟合方法： 
	硬方法：数据增强、Dropout、减小网络规模、调整超参数（训练轮数调整-->早熟）	--> 详细见AI Assignment3
	软方法：权重限制（权重共享、Layer权重正则化、值与梯度一起训练）、调整Layer的激活函数为Leaky Relu, Selu 等方法（避免神经元死亡和梯度消失带来的影响、 Batch Normalization
利用现有网络方法：   特征提取、模型微调	--> 详细见《Python深度学习》

提升模型性能的方法（以YOLO为例）：
	1. Batch Normalization           （mAP提升幅度：2.4）
	批归一化有助于解决反向传播过程中的梯度消失和梯度爆炸问题，降低对一些超参数（比如学习率、网络参数的大小范围、激活函数的选择）的敏感性，并且每个batch分别进行归一化的时候，起到了一定的正则化效果（如YOLO2不再使用dropout），从而能够获得更好的收敛速度和收敛效果。
	模型一次训练会输入一批样本，批规一化在神经网络的每一层（在网络（线性变换）输出后和激活函数（非线性变换）之前）增加一个批归一化层（BN），BN层进行如下变换：①对该批样本的各特征量（对于中间层来说，就是每一个神经元）分别进行归一化处理，分别使每个特征的数据分布变换为均值0，方差1。从而使得每一批训练样本在每一层都有类似的分布。这一变换不需要引入额外的参数。②对上一步的输出再做一次线性变换，假设上一步的输出为Z，则Z1=γZ + β。这里γ、β是可以训练的参数。增加这一变换是因为上一步骤中强制改变了特征数据的分布，可能影响了原有数据的信息表达能力。增加的线性变换使其有机会恢复其原本的信息
	2. 微调模型           （mAP提升幅度：3.7）
	YOLO v1使用ImageNet的图像分类样本采用 224*224 作为输入，来训练CNN卷积层。然后在训练对象检测时，检测用的图像样本采用更高分辨率的 448*448 的图像作为输入。但这样切换对模型性能有一定影响。
	微调模型-->
	YOLO2在采用 224*224 图像进行分类模型预训练后，再采用 448*448 的高分辨率样本对分类模型进行微调（10个epoch， 使用较少的轮数进行微调），使网络特征逐渐适应 448*448 的分辨率。然后再使用 448*448 的检测样本进行训练，缓解了分辨率突然切换造成的影响
	3. 采用Anchor box           （mAP提升幅度：4.8）
	之前YOLO1并没有采用先验框，并且每个grid只预测两个bounding box，整个图像98个。YOLO2每个grid采用9个先验框，总共有13*13*9=1521个先验框。所以，相对YOLO1的81%的召回率，YOLO2的召回率大幅提升到88%.
	Further improvement   1 --> 聚类提取先验框尺度
	Faster R-CNN 系列先验框都是手工设定的，YOLO2尝试统计出更符合样本中对象尺寸的先验框，这样就可以减少网络微调先验框到实际位置的难度。YOLO2的做法是对训练集中标注的边框进行聚类分析，以寻找尽可能匹配样本的边框尺寸。YOLO2选择k=5作为边框数量与IOU的折中。对比手工选择的先验框，使用5个聚类框即可达到61 Avg IOU，相当于9个手工设置的先验框60.9 Avg IOU。
	Further improvement   2 --> 约束先验框位置
	YOLO1中，t_x,t_y的取值没有任何约束，因此预测边框的中心可能出现在任何位置，训练早期阶段不容易稳定。YOLO调整了预测公式，将预测边框的中心约束在特定gird网格内
	4. passthrough层检测细粒度特征           （mAP提升幅度：1）
	对象检测面临的一个问题是图像中对象会有大有小，输入图像经过多层网络提取特征，最后输出的特征图中（比如YOLO2中输入416*416经过卷积网络下采样最后输出是13*13），较小的对象可能特征已经不明显甚至被忽略掉了。为了更好的检测出一些比较小的对象，最后输出的特征图需要保留一些更细节的信息。
	YOLO2引入一种称为passthrough层的方法在特征图中保留一些细节信息。具体来说，就是在最后一个pooling之前，特征图的大小是26*26*512，将其1拆4，直接传递（passthrough）到pooling后（并且又经过一组卷积）的特征图，两者叠加到一起作为输出的特征图。
	5. 多尺度输入           （mAP提升幅度：1.4）
	使用多尺度的输入能使网络能够适应各种大小的对象检测。因为去掉了全连接层，YOLO2可以输入任何尺寸的图像。训练时每10个batch就随机更换一种尺寸。
	6. 分阶段训练	阶段一：特征提取 	阶段二：模型微调。
	经典方法：
	利用已有的成熟模型的卷积基+ 全连接层  构造当前模型，在End-to-End training之后，冻住模型，解冻最后3-4层，使用与实际预测数据契合度较高的数据进行训练，微调模型使得模型进一步学习到任务相关性较高层次的特征）
	YOLO2:
	YOLO2的训练主要包括三个阶段。
	第一阶段就是先在ImageNet分类数据集上预训练Darknet-19，此时模型输入为 224*224 ，共训练160个epochs。
	然后第二阶段将网络的输入调整为 448*448 ，继续在ImageNet数据集上finetune分类模型，训练10个epochs，此时分类模型的top-1准确度为76.5%，而top-5准确度为93.3%。
	第三个阶段就是修改Darknet-19分类模型为检测模型，移除最后一个卷积层、global avgpooling层以及softmax层，并且新增了三个 3*3*1024卷积层，同时增加了一个passthrough层，最后使用 1*1 卷积层输出预测结果，输出的channels数为：num_anchors*(5+num_classes) ，和训练采用的数据集有关系。由于anchors数为5，对于VOC数据集（20种分类对象）输出的channels数就是125，最终的预测矩阵T的shape为 (batch_size, 13, 13, 125)，可以先将其reshape为 (batch_size, 13, 13, 5, 25) ，其中 T[:, :, :, :, 0:4] 为边界框的位置和大小 ，T[:, :, :, :, 4] 为边界框的置信度，而 T[:, :, :, :, 5:] 为类别预测值。
	7. 采样以平衡数据集
	由于ImageNet样本比COCO多得多，所以对COCO样本会多做一些采样（oversampling），适当平衡一下样本数量，使两者样本数量比为4:1。
	8. 多标签优化、多尺度检测（YOLO3 相比YOLO2）
	YOLO3预测对象类别时不使用softmax，改成使用logistic的输出进行预测。这样能够支持多标签对象（比如一个人有Woman 和 Person两个标签）。
	YOLO3借鉴了残差网络结构，形成更深的网络层次，以及多尺度检测，提升了mAP及小物体检测效果。










########################################
Specific Explanation:
	残差网络residual network在一些层之间设置了快捷链路（shortcut connections）。